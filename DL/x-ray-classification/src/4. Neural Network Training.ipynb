{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfc96007-45fa-4ad7-98c7-12413c5676d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02b9f26-6287-45c3-bbbf-c449c67142ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "base_dir = \"/Volumes/users/kevin_romero/kaggle/x-ray-kaggle/chest-xray-pneumonia/chest_xray_aug\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"val\")\n",
    "\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "n_to_move = 100\n",
    "\n",
    "for cls in classes:\n",
    "    src_dir = os.path.join(train_dir, cls)\n",
    "    dst_dir = os.path.join(val_dir, cls)\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # list files in source class directory\n",
    "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "    random.shuffle(files)\n",
    "\n",
    "    # take up to n_to_move files (handles case where there are fewer than 100)\n",
    "    to_move = files[:n_to_move]\n",
    "\n",
    "    print(f\"Moving {len(to_move)} files from {src_dir} to {dst_dir} ...\")\n",
    "\n",
    "    for fname in to_move:\n",
    "        src = os.path.join(src_dir, fname)\n",
    "        dst = os.path.join(dst_dir, fname)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8e524d-c11d-4c9a-ab16-8f1e93f4cf21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "volume = \"/Volumes/users/kevin_romero/kaggle/x-ray-kaggle/chest-xray-pneumonia/chest_xray_aug/\"\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    volume + \"train\",\n",
    "    label_mode=\"binary\",\n",
    "    image_size=(512, 512),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    volume + \"val\",\n",
    "    label_mode=\"binary\",\n",
    "    image_size=(512, 512),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    volume + \"test\",\n",
    "    label_mode=\"binary\",\n",
    "    image_size=(512, 512),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dcb5c36-26bd-4b83-b3fd-1d5a9d0ad6c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Load Pre-trained DenseNet121\n",
    "model = models.densenet121(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 2. Modify the First Layer (Handle Grayscale)\n",
    "# ImageNet expects 3 channels (RGB). X-rays are 1 channel (Gray).\n",
    "# Option A: Repeat the X-ray channel 3 times (easy).\n",
    "# Option B: Change the first conv layer (better for compute).\n",
    "original_conv = model.features.conv0\n",
    "model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Copy weights from the original RGB filters (average them to making a grayscale filter)\n",
    "with torch.no_grad():\n",
    "    model.features.conv0.weight[:] = torch.mean(original_conv.weight, dim=1, keepdim=True)\n",
    "\n",
    "# 3. Modify the Last Layer (Classifier)\n",
    "num_features = model.classifier.in_features\n",
    "# Change output to 1 (for binary: Sick vs Healthy) or N (for multi-class)\n",
    "model.classifier = nn.Linear(num_features, 1) \n",
    "\n",
    "# 4. Loss & Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.0])) # Weight for imbalance\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cd9bfea-9302-4c38-b03b-a906652237f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# X-rays are grayscale; map to 3 channels\n",
    "def preprocess(x, y):\n",
    "    x = tf.image.grayscale_to_rgb(x)\n",
    "    x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds_pp = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "val_ds_pp   = val_ds.map(preprocess,   num_parallel_calls=AUTOTUNE)\n",
    "test_ds_pp  = test_ds.map(preprocess,  num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    input_shape=(512, 512, 3),\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False  # first train only the head\n",
    "\n",
    "inputs = layers.Input(shape=(512, 512, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91242e96-ac4b-4f34-9288-8600f346f4f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds_pp,\n",
    "    validation_data=val_ds_pp,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Fineâ€‘tune\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"],\n",
    ")\n",
    "history_ft = model.fit(\n",
    "    train_ds_pp,\n",
    "    validation_data=val_ds_pp,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf0e294-3f7d-4058-ab87-c0bb1240c2f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "y_true = np.concatenate([y for _, y in val_ds_pp])\n",
    "y_pred = model.predict(val_ds_pp).ravel()\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "for t in [0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    y_hat = (y_pred >= t).astype(int)\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    sens = tp / (tp + fn + 1e-8)  # recall for positive\n",
    "    spec = tn / (tn + fp + 1e-8)\n",
    "    print(f\"thr={t:.2f} acc={acc:.3f} sens={sens:.3f} spec={spec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1049f646-1d55-41d4-862d-8749ce035012",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Save full model (architecture + weights + optimizer)\n",
    "model.save(\"/Workspace/Users/kevin.romero@databricks.com/Personal/databricks-free-edition-projects/DL/x-ray-classification/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b74d656a-8a3b-4bc0-bea1-921bd15660a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"/Workspace/Users/kevin.romero@databricks.com/Personal/databricks-free-edition-projects/DL/x-ray-classification/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7afe162-0e13-4018-904a-fb28e7202c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "best_thr = 0.6  # or whichever you like from the printout\n",
    "y_hat = (y_pred >= best_thr).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "print(\"TN, FP, FN, TP:\", tn, fp, fn, tp)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "databricks_ai_v4",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6482493832308791,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "4. Neural Network Training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
