{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be8f8c29-9f18-4d1b-aefa-676923064a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Read variables\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "dataset = dbutils.widgets.get(\"dataset\")\n",
    "\n",
    "path = f\"{catalog}.{schema}.{dataset}\"\n",
    "print(f\"Iris Dataset Path: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ac2608-a64b-4175-8e99-fc6ad48f11cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# Setup: libraries, MLflow experiment/registry, and config\n",
    "import os\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from mlflow import sklearn as mlflow_sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Databricks feature engineering\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "# Config\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Unity Catalog table with Iris data\n",
    "    source_table: str = path\n",
    "    # Primary key present in the table (see attached schema screenshot)\n",
    "    primary_key: str = \"id\"\n",
    "    # Target column name\n",
    "    target_col: str = \"species\"\n",
    "    # Registered model name in Unity Catalog\n",
    "    registered_model: str = f\"{catalog}.{schema}.iris_rf_classifier\"\n",
    "    # MLflow experiment path (use a workspace path so it shows in UI)\n",
    "    experiment_path: str = \"/Shared/MLflow Experiments/iris_feature_store_demo\"\n",
    "    # minimum F1 score required for production\n",
    "    f1_threshold: float = 0.80\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# Point MLflow to the desired experiment\n",
    "mlflow.set_experiment(CFG.experiment_path)\n",
    "\n",
    "# Initialize Feature Engineering client\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "print(f\"Experiment set to: {mlflow.get_experiment_by_name(CFG.experiment_path).experiment_id}\")\n",
    "print(f\"Registered model: {CFG.registered_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08968075-20f8-4bdf-92e4-47e115ace1ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create or use a Feature Engineering feature table for Iris\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "feature_table_name = CFG.source_table\n",
    "\n",
    "# Create a managed feature table if it doesn't exist, directly from the source Unity Catalog table\n",
    "# Note: In real projects, you might build features with transformations; here we pass through numeric columns\n",
    "numeric_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "\n",
    "source_df = spark.read.table(CFG.source_table).select(CFG.primary_key, *numeric_cols, CFG.target_col)\n",
    "\n",
    "from databricks.feature_engineering import FeatureLookup\n",
    "\n",
    "# Build a training set from the feature table; label is in the source table\n",
    "feature_lookups = [\n",
    "    FeatureLookup(\n",
    "        table_name=feature_table_name,\n",
    "        lookup_key=CFG.primary_key,\n",
    "        feature_names=numeric_cols,\n",
    "    )\n",
    "]\n",
    "\n",
    "training_set = fe.create_training_set(\n",
    "    df=source_df.select(CFG.primary_key, CFG.target_col),\n",
    "    feature_lookups=feature_lookups,\n",
    "    label=CFG.target_col,\n",
    ")\n",
    "\n",
    "training_pd = training_set.load_df().toPandas()\n",
    "\n",
    "X = training_pd[numeric_cols].astype(float)\n",
    "y = training_pd[CFG.target_col].astype(str)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Shapes - train: {X_train.shape}, val: {X_val.shape}, test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89e5830-ee4f-42d0-89d2-2dad2031ccbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train with MLflow autolog\n",
    "import json\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.sklearn.autolog(log_models=True)\n",
    "run_params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": None,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"iris_rf_training\") as run:\n",
    "    clf = RandomForestClassifier(**run_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation\n",
    "    val_preds = clf.predict(X_val)\n",
    "    f1_val = f1_score(y_val, val_preds, average=\"weighted\")\n",
    "    mlflow.log_metric(\"f1_val\", float(f1_val))\n",
    "    mlflow.log_dict({\"numeric_features\": list(X.columns)}, \"features.json\")\n",
    "\n",
    "    # Final test metrics\n",
    "    test_preds = clf.predict(X_test)\n",
    "    f1_test = f1_score(y_test, test_preds, average=\"weighted\")\n",
    "    mlflow.log_metric(\"f1_test\", float(f1_test))\n",
    "\n",
    "    # Prepare example and signature\n",
    "    input_example = X_train.iloc[:3]\n",
    "    signature = infer_signature(X_train, clf.predict(X_train))\n",
    "\n",
    "    # Log and register the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=CFG.registered_model,\n",
    "    )\n",
    "\n",
    "    challenger_model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    print(\"Validation F1:\", f1_val, \" Test F1:\", f1_test)\n",
    "    print(\"Model URI:\", challenger_model_uri)\n",
    "\n",
    "challenger_run = mlflow.last_active_run()\n",
    "challenger_run_id = challenger_run.info.run_id if challenger_run is not None else None\n",
    "print(\"challenger Run:\", challenger_run_id)\n",
    "\n",
    "# Assign the “challenger” alias to the newly created model version\n",
    "client = MlflowClient()\n",
    "versions = client.search_model_versions(f\"name='{CFG.registered_model}'\")\n",
    "if not versions:\n",
    "    raise RuntimeError(\"No versions found for registered model.\")\n",
    "# Sort by version integer descending\n",
    "versions_sorted = sorted(versions, key=lambda mv: int(mv.version), reverse=True)\n",
    "most_recent = versions_sorted[0]\n",
    "client.set_registered_model_alias(\n",
    "    name=CFG.registered_model,\n",
    "    alias=\"challenger\",\n",
    "    version=most_recent.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3234c3-9fac-4dc3-a7d0-25fbfce0e790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "model_name = CFG.registered_model\n",
    "production_alias = \"champion\"\n",
    "\n",
    "# Get the latest version of the registered model\n",
    "all_versions = mlflow_client.search_model_versions(f\"name='{model_name}'\")\n",
    "latest_version = max(int(v.version) for v in all_versions)\n",
    "latest_model = mlflow_client.get_model_version(model_name, str(latest_version))\n",
    "\n",
    "# Retrieve F1 score for the latest version\n",
    "run = mlflow_client.get_run(latest_model.run_id)\n",
    "latest_f1 = run.data.metrics.get(\"f1_val\") or run.data.metrics.get(\"f1\")\n",
    "\n",
    "# Retrieve F1 score for the current champion version (if it exists)\n",
    "try:\n",
    "    champ_model = mlflow_client.get_model_version_by_alias(model_name, production_alias)\n",
    "    champ_run = mlflow_client.get_run(champ_model.run_id)\n",
    "    champ_f1 = champ_run.data.metrics.get(\"f1_val\") or champ_run.data.metrics.get(\"f1\")\n",
    "except MlflowException:\n",
    "    # No existing champion alias; treat its F1 as the lowest possible\n",
    "    champ_f1 = float(\"-inf\")\n",
    "\n",
    "print(f\"Latest version: {latest_version}, F1 score: {latest_f1:.4f}\")\n",
    "print(f\"Champion version: {getattr(champ_model, 'version', None)}, F1 score: {champ_f1:.4f}\")\n",
    "\n",
    "# Promote to champion only if it outperforms the current champion\n",
    "if latest_f1 > champ_f1:\n",
    "    mlflow_client.set_registered_model_alias(\n",
    "        name=model_name,\n",
    "        version=str(latest_version),\n",
    "        alias=production_alias\n",
    "    )\n",
    "    print(f\"Promoted version {latest_version} to '{production_alias}' (F1 {latest_f1:.4f} > {champ_f1:.4f})\")\n",
    "else:\n",
    "    print(f\"Skipping promotion: latest F1 {latest_f1:.4f} ≤ champion F1 {champ_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks-feature-engineering"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. Model Training",
   "widgets": {
    "catalog": {
     "currentValue": "workspace",
     "nuid": "dc4b55ad-50fd-42d2-b8fd-d2ca0e398ef8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "dataset": {
     "currentValue": "iris_species",
     "nuid": "47085ec4-dda5-4603-b1cd-9f951ae1f34d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "dataset",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "dataset",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "iris",
     "nuid": "536ed255-efb5-44d1-8223-4bca3fe814cb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
