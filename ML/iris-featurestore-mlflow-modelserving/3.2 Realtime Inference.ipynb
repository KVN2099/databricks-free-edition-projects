{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realtime Inference: Iris RandomForest via Databricks Model Serving\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Configuration\n",
    "ENDPOINT_NAME = \"iris-rf-realtime-endpoint\"\n",
    "REGISTERED_MODEL = \"workspace.iris.iris_rf_classifier\"\n",
    "MODEL_ALIAS = \"champion\"\n",
    "WORKLOAD_SIZE = \"Small\"\n",
    "SCALE_TO_ZERO = True\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "served_model_name = \"iris_rf_served_model\"\n",
    "\n",
    "config = {\n",
    "    \"served_models\": [\n",
    "        {\n",
    "            \"name\": served_model_name,\n",
    "            \"model_name\": REGISTERED_MODEL,\n",
    "            \"model_alias\": MODEL_ALIAS,\n",
    "            \"workload_size\": WORKLOAD_SIZE,\n",
    "            \"scale_to_zero_enabled\": SCALE_TO_ZERO\n",
    "        }\n",
    "    ],\n",
    "    \"traffic_config\": {\n",
    "        \"routes\": [\n",
    "            {\"served_model_name\": served_model_name, \"traffic_percentage\": 100}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Upsert endpoint\n",
    "try:\n",
    "    endpoint = w.serving_endpoints.create(name=ENDPOINT_NAME, config=config)\n",
    "    print(f\"Created endpoint '{ENDPOINT_NAME}'.\")\n",
    "except Exception:\n",
    "    # If it already exists, update its config\n",
    "    endpoint = w.serving_endpoints.update_config(\n",
    "        name=ENDPOINT_NAME,\n",
    "        served_models=config[\"served_models\"],\n",
    "        traffic_config=config[\"traffic_config\"]\n",
    "    )\n",
    "    print(f\"Updated endpoint '{ENDPOINT_NAME}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigSummaryConfig\n",
    "\n",
    "# Wait for endpoint to be ready\n",
    "print(f\"Waiting for endpoint '{ENDPOINT_NAME}' to be ready...\")\n",
    "\n",
    "terminal_states = {\"READY\", \"UPDATE_FAILED\"}\n",
    "start_time = time.time()\n",
    "\n",
    "def _get_state():\n",
    "    ep = w.serving_endpoints.get(ENDPOINT_NAME)\n",
    "    return ep.state.ready, ep\n",
    "\n",
    "while True:\n",
    "    ready_state, ep = _get_state()\n",
    "    # ready_state examples: \"READY\", \"NOT_READY\", \"UPDATE_FAILED\"\n",
    "    print(f\"State: {ready_state}\")\n",
    "    if ready_state in terminal_states:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "elapsed = int(time.time() - start_time)\n",
    "print(f\"Endpoint state after {elapsed}s: {ready_state}\")\n",
    "\n",
    "if ready_state != \"READY\":\n",
    "    raise RuntimeError(f\"Endpoint failed to become READY. Last state: {ready_state}\")\n",
    "\n",
    "# Show served models summary\n",
    "summary = w.serving_endpoints.get(ENDPOINT_NAME)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare a sample Iris row (sepal_length, sepal_width, petal_length, petal_width)\n",
    "sample = pd.DataFrame([\n",
    "    {\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}\n",
    "])\n",
    "\n",
    "# Invoke endpoint\n",
    "# \"inputs\" payload supports 'dataframe_records' for pandas-style records\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"inputs\",\n",
    "            \"shape\": [len(sample), len(sample.columns)],\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"dataframe_records\": sample.to_dict(orient=\"records\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "invocation = w.serving_endpoints.query(name=ENDPOINT_NAME, dataframe_records=payload[\"inputs\"][0][\"dataframe_records\"])  # type: ignore\n",
    "print(\"Raw response:\\n\", invocation)\n",
    "\n",
    "# Best-effort parse of common MLflow serving output formats\n",
    "try:\n",
    "    # Newer SDKs return structured QueryEndpointResponse\n",
    "    preds = getattr(invocation, \"predictions\", None)\n",
    "    if preds is None and isinstance(invocation, dict):\n",
    "        preds = invocation.get(\"predictions\")\n",
    "    print(\"Predictions:\", preds)\n",
    "except Exception as e:\n",
    "    print(\"Could not parse predictions:\", e)\n",
    "    print(invocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d52f1600-ef91-4bc8-9bb1-2e4b0466fbb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.2 Realtime Inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
